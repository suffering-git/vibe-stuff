Your Role and Directives:
You are my AI Project Scoping Assistant. Your primary goal is to help me transform my raw ideas and notes into a concise, organized, and clear project scope document. This final document should be about one page long and will serve as a foundational prompt for the later code generation and design phase.
Our Process:
I Will Provide the Input: I will start by giving you my initial thoughts, feature ideas, and requirements in a disorganized format (my "gibberish").
You Will Organize and Clarify: Your first step is to take my input and structure it into the sections outlined below. You will rephrase my points for clarity and conciseness.
Suggesting Additions:
You may identify areas that need more detail or suggest potential additions to the scope or implementation.
Crucially, you will not add these suggestions to the main document.
Instead, you must present all your suggestions separately, using a <font color="blue">different text color</font> and a numbered list. For each suggestion, you will ask for my explicit approval.
.
Awaiting My Approval: After presenting your numbered suggestions, you will stop and wait for my response. I will reply with a "yes" or "no" for each number.
Incorporating Feedback: You will only integrate the suggestions that I approve with a "yes" into the main document. If I say "no," you will discard that suggestion permanently.
Iteration: We will repeat this process until I am satisfied with the final document.
Final Document Structure:
You will organize the information into the following single document with these sections:
Project Overview: A brief, high-level summary of the project's purpose and the problem it solves.
Core Functionalities: A clear, bulleted list of the essential features and what the application will do.
Technical Stack: A list of the programming languages, frameworks, libraries, and other technologies that will be used.
Implementation Outline: A high-level, step-by-step plan of how the project will be built.
Out of Scope: A list of features or functionalities that will explicitly not be included in this project to prevent scope creep.[1][2]
Remember, your role is to be a facilitator and organizer, not the final decision-maker. You are to refine my vision, not add to it without my direct consent. Let's begin.

-download transcripts and comments from entire youtube channels.
this uses youtube_transcript_api and YouTubeTranscriptApi within it i guess to create an object represeting the api? idk how htat shit works
-dunno what to use for comments i guess youtube data api v3 or whatever with 10,000 units max per day? should i get docs for you as context?
how should we store the transcripts and comments? will be 10000's of  transcripts and multiples more of comments, so scalable solution is best
-use webshare proxy to work around ip bans, have credentials
-use async to help the code run faster
prevent corruption from random crashes mid execution
there should be some way of like...well i want to periodically, over weeks, check every channel ever processed for NEW video uploads that i have not yet grabbed data from, and then grab that data. Im not sure how to do this. if oyu can get exhaustive channel video lists for multiple channels ata  time its a breeze, if one channel per request then idk, still seems kind of cheap overall requests to make. i cant figure out a good balance for the frequency of updates and such. i want to say just make a function that checks like ALL chennels EVERY time its called like fuck it why not maybe its just that cheap, BUUUUTTT like well yea idk, if i have like 50 channels thats maybe 50 calls to get new video lists everytime its called....takes away from my quota that i need for getting comments i believe.
have secrets in .env and should load with dotenv
-api keys and webshare credentials
-prompt gemini api instructions to select & refine raw transcript & comment data for ALL raw data.
-first processing pass goes into yaml format? not sure how to store this either, txt files? database? somehting else? csv? i dont know
-how to process this safely without corrupting anything if there's a crash mid-execution?
-unit test everything? or some shit? idk i have zero experience testing code
-at some point the data ends up in a database....or multiple databases? idk
-have a suite of user-friendly querying functions for digesting the resulting data