***

### **Project Scope: YouTube Data Scraper & Processor v2.1 (Technical Specification)**

#### **Project Summary**
A Python-based tool to download video transcripts and comments from YouTube channels for market research. The goal is to inform a market garden and orchard business plan focused on regenerative agriculture. The system performs a multi-stage AI processing pipeline on the raw data, structuring it into a normalized database of contextual summaries and atomic insights. A human-in-the-loop workflow allows for the iterative development and application of a curated set of descriptive tags.

#### **Core Features / User Stories**
*   **Downloads Raw Data:** Downloads all video transcripts and comments for specified channels, saving each as a raw `.json` file.
*   **Automated Translation:** Automatically translates all non-English transcripts to English during the initial download phase.
*   **Resumable Processing:** A robust status tracking system ensures that if the script is stopped or crashes at any point, it can be resumed without re-doing completed work.
*   **Structured AI Analysis:** A logical 2-stage AI pipeline filters raw text, then extracts it into two distinct data types: full-paragraph `ContextSummaries` and multiple, queryable `StructuredInsights` linked to each summary.
*   **Iterative Tagging System:** Provides a suite of scripts for a human-in-the-loop workflow to discover, curate, and retroactively apply a consistent set of tags to all insights in the database.
*   **High-Performance Search:** Implements a full-text search capability allowing for complex, high-speed queries across all contextual summaries and atomic insight text.
*   **Experimentation via Processing Runs:** Allows for the entire analysis pipeline to be re-run with different prompts or models, storing the results as a distinct and comparable "Processing Run."
*   **Consistent Testing Environment:** Allows a user to define and manage a persistent control sample of videos for consistent, comparable prompt/model testing.
*   **Simplified Query Interface:** Provides a suite of user-friendly Python functions (in `query_utils.py`) for retrieving data from the database without needing to write raw SQL.

#### **Technical Stack**
*   **Programming Language:** Python
*   **Dependency Management:** A `requirements.txt` file will list all necessary packages and their versions for reproducible environments.
*   **Key Libraries:**
    *   `youtube_transcript_api`: For fetching video transcripts.
    *   `google-api-python-client`: The official Google client for interacting with the YouTube Data API v3 to fetch comments and video metadata.
    *   `asyncio`: For performing concurrent transcript downloads to improve speed when using proxies.
    *   `python-dotenv`: To load credentials (API keys, proxy info) from a `.env` file into the script's environment.
    *   `google-generativeai`: The SDK for making calls to the Gemini API for all AI processing stages.
    *   `sqlite3`: The built-in Python library for interacting with the SQLite database file.
*   **Services:** Webshare (for proxies), YouTube Data API v3, Gemini API.
*   **Database:** SQLite, with the **FTS5 (Full-Text Search 5) extension** enabled for high-performance text queries.

#### **Implementation Details / Logic**
*   **Configuration:** A central `config.py` file will manage all user-configurable settings, including `file paths` for raw data and outputs, the `list of target YouTube channels`, all `API parameters` (e.g., model names for each AI stage), and `update intervals` (the number of days to wait before re-checking a channel for new videos).
*   **Credentials:** All sensitive credentials (YouTube API Key, Gemini API Key, Webshare proxy credentials) will be stored in a `.env` file and loaded into the script's environment using the `python-dotenv` library.
*   **Idempotency & State Management:** The entire pipeline will be resumable and will not repeat completed work.
    *   **Primary Mechanism:** A `VideoProcessingStatus` table in the database will have one row for every video and will track its state (e.g., `transcript_status`, `comments_status`, `processing_stage`). Before any action is taken on a video, the script will first query this table to check its status.
    *   **Optimization:** The initial data download script will first perform a simple `os.path.exists()` check. If a raw `.json` file for a given `video_id` already exists, it will skip that video immediately, reducing unnecessary database queries.
*   **Data Fetching & Translation:**
    *   **Transcripts:** Fetched via asynchronous requests routed through Webshare proxies to mitigate IP bans and improve speed. The logic will first list available transcript languages, preferably fetch English, but otherwise fetch an available language and immediately translate it to English using the `youtube_transcript_api`'s built-in `.translate('en')` method.
    *   **Comments:** Fetched via sequential, synchronous requests to the YouTube Data API. A `time.sleep()` call of a configurable duration will be placed between each request to ensure rate limits are respected.
*   **Data Integrity (Atomic Writes):** To prevent file corruption from a crash during a write operation, the system will employ an atomic write pattern: write all data to a temporary file (e.g., `video_id.json.tmp`), and only upon successful completion, perform a final, atomic `os.rename()` to its permanent name (e.g., `video_id.json`).
*   **Error Handling:** The script will not crash on non-critical errors.
    *   **Permanent Errors:** If the YouTube API reports that transcripts are disabled or comments are disabled for a video, the `VideoProcessingStatus` table will be updated with a final state (e.g., 'unavailable', 'disabled'), and the specific error message will be logged. The video will be skipped in all future runs.
    *   **Transient Errors:** For network timeouts, proxy connection errors, or temporary API rate limits, the error will be logged with a full traceback, but the video's status in the database will remain unchanged, making it eligible to be retried automatically on the next script run.
*   **AI Processing Pipeline (2-Stage):**
    *   **Stage 1 (Filter & Classify):** **Input:** Raw text from a transcript or comment. **Process:** A cost-effective model (e.g., Gemini Flash) is prompted to discard irrelevant content and classify the remainder. **Output:** A classification (`Quantitative` or `Actionable Insight`) and the filtered text, which are then passed to the next stage.
    *   **Stage 2 (Analyze & Extract):** **Input:** The filtered text and its classification from Stage 1. **Process:** A powerful model (e.g., Gemini Pro) is prompted to perform two distinct actions: 1) generate a comprehensive `full_text_blurb` for the `ContextSummaries` table, and 2) extract all relevant atomic details into separate `StructuredInsights` records. **Output:** The data needed to populate the two primary data tables.
*   **Tag Generation Workflow (Human-in-the-loop):**
    *   **1. Initial Run:** The main script runs, leaving the `tags_json` column in `StructuredInsights` null.
    *   **2. Discovery:** A dedicated `discover_tags.py` script suggests tags based on a sample of the data, saving these raw suggestions to a **`discovered_tags.json`** file.
    *   **3. Curation:** The user manually edits `discovered_tags.json`. This file acts as a persistent workbench, safely storing the user's iterative progress.
    *   **4. Committing:** When satisfied, the user runs a command (`python manage_tags.py --commit`) which copies the curated tags from the workbench file to the final **`authoritative_tags.json`** file.
    *   **5. Application:** A separate `apply_tags.py` script reads the authoritative tag list and uses an AI prompt to populate the `tags_json` column for all untagged insights in the database.
*   **Full-Text Search (FTS):** The system will use SQLite's FTS5 extension.
    *   A virtual table (`ContextSummaries_fts`) will be created to index the `full_text_blurb` column for searching through the contextual summaries.
    *   A hidden `_fts_text` column in the `StructuredInsights` table will contain a concatenation of all text from its row (`summary_sentence` and all tags). A second virtual table (`StructuredInsights_fts`) will index this column, enabling unified search across all atomic data.
*   **Raw Data Migration:** A one-time utility script (`migrate_transcripts.py`) will be provided to convert any legacy `.txt` transcript files into the new standardized JSON container format. The new format is: `{"video_id": "...", "video_title": "...", "channel_id": "...", "channel_name": "...", "transcript": "..."}`.

#### **Data Model / Schema**
*   **Database Indexing:** To ensure fast queries, the foreign key columns (`run_id`, `video_id` in `ContextSummaries`, and `summary_id` in `StructuredInsights`) will be explicitly indexed.
*   **Database Schema:**

    *   **`Channels` Table**
        *   `channel_id` (TEXT, Primary Key) --- *The unique YouTube channel ID (e.g., UC295-Dw_tDNtZXFeAPAW6Aw).*
        *   `channel_name` (TEXT) --- *The human-readable name of the channel.*

    *   **`Videos` Table**
        *   `video_id` (TEXT, Primary Key) --- *The unique YouTube video ID (e.g., dQw4w9WgXcQ).*
        *   `channel_id` (TEXT, Foreign Key) --- *Links to the `Channels` table.*
        *   `video_title` (TEXT) --- *The title of the video.*
        *   `published_date` (DATETIME) --- *The original upload date of the video.*
        *   `duration_seconds` (INTEGER) --- *The length of the video in seconds.*
        *   `view_count` (INTEGER) --- *The view count at the time of metadata fetching.*
        *   `like_count` (INTEGER) --- *The like count at the time of metadata fetching.*

    *   **`VideoProcessingStatus` Table**
        *   `video_id` (TEXT, Primary Key, Foreign Key referencing `Videos`) --- *Links to the `Videos` table.*
        *   `transcript_status` (TEXT) --- *e.g., 'pending', 'downloaded', 'unavailable'.*
        *   `comments_status` (TEXT) --- *e.g., 'pending', 'downloaded', 'disabled'.*
        *   `processing_stage` (TEXT) --- *Tracks progress through the AI pipeline (e.g., 'pending', 'stage_1_complete', 'stage_2_complete').*
        *   `last_updated` (DATETIME) --- *Timestamp of the last status change for this video.*

    *   **`ProcessingRuns` Table**
        *   `run_id` (INTEGER, Primary Key) --- *Unique identifier for a single execution of the AI pipeline.*
        *   `run_name` (TEXT) --- *A user-friendly name for the run (e.g., "v1-gemini-pro-test").*
        *   `model_version` (TEXT) --- *The specific AI model used for the analysis stage.*
        *   `prompt_text` (TEXT) --- *The full text of the Stage 2 prompt used.*
        *   `run_date` (DATETIME) --- *When the processing run was initiated.*

    *   **`ContextSummaries` Table**
        *   `summary_id` (INTEGER, Primary Key) --- *Unique identifier for each distinct contextual blurb.*
        *   `run_id` (INTEGER, Foreign Key) --- *Links to the `ProcessingRuns` table.*
        *   `video_id` (TEXT, Foreign Key) --- *Links to the `Videos` table.*
        *   `full_text_blurb` (TEXT) --- *The full, AI-generated paragraph summary providing rich context.*

    *   **`StructuredInsights` Table**
        *   `insight_id` (INTEGER, Primary Key) --- *Unique identifier for each atomic insight.*
        *   `summary_id` (INTEGER, Foreign Key referencing `ContextSummaries`) --- *Links each insight back to its source blurb.*
        *   `insight_type` (TEXT) --- *The classification from Stage 1, expecting `"Quantitative"` or `"Actionable Insight"`.*
        *   `confidence_score` (INTEGER) --- *The AI's score (1-100) of the insight's relevance and value.*
        *   `summary_sentence` (TEXT) --- *A single, concise sentence that describes this specific atomic insight.*
        *   `key_values_json` (TEXT) --- *A JSON object for data with specific numerical or string values (e.g., `{"price": 10.00, "employees": 1}`).*
        *   `tags_json` (TEXT) --- *A JSON array of strings from the `authoritative_tags.json` file (e.g., `["lettuce", "pricing"]`).*
        *   `_fts_text` (TEXT, HIDDEN) --- *A non-visible column containing concatenated text from this row for the search index.*

#### **Testing**
*   A set of simple test scripts will be created to verify core workflows, such as processing a single pre-downloaded video file to ensure the AI pipeline stages produce the expected outputs.